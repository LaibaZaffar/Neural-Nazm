{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBsaZ-lebh9P",
        "outputId": "b623ba1f-4267-4195-86d8-87dbd26db659"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.0539 - loss: 6.9861"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 112ms/step - accuracy: 0.0539 - loss: 6.9859 - val_accuracy: 0.0736 - val_loss: 6.5051\n",
            "Epoch 2/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.0753 - loss: 6.3865"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 111ms/step - accuracy: 0.0754 - loss: 6.3864 - val_accuracy: 0.0810 - val_loss: 6.4333\n",
            "Epoch 3/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.0883 - loss: 6.1958"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.0883 - loss: 6.1958 - val_accuracy: 0.0953 - val_loss: 6.3887\n",
            "Epoch 4/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.0995 - loss: 6.0382"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.0995 - loss: 6.0382 - val_accuracy: 0.0991 - val_loss: 6.3878\n",
            "Epoch 5/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 111ms/step - accuracy: 0.1075 - loss: 5.9236 - val_accuracy: 0.1042 - val_loss: 6.3920\n",
            "Epoch 6/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 111ms/step - accuracy: 0.1147 - loss: 5.7884 - val_accuracy: 0.1067 - val_loss: 6.4155\n",
            "Epoch 7/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 111ms/step - accuracy: 0.1179 - loss: 5.6926 - val_accuracy: 0.1100 - val_loss: 6.4426\n",
            "Epoch 8/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 111ms/step - accuracy: 0.1228 - loss: 5.5877 - val_accuracy: 0.1107 - val_loss: 6.4895\n",
            "Epoch 9/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 110ms/step - accuracy: 0.1268 - loss: 5.4704 - val_accuracy: 0.1126 - val_loss: 6.5480\n",
            "Epoch 10/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 110ms/step - accuracy: 0.1328 - loss: 5.3622 - val_accuracy: 0.1122 - val_loss: 6.6514\n",
            "Epoch 11/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 109ms/step - accuracy: 0.1355 - loss: 5.2652 - val_accuracy: 0.1148 - val_loss: 6.7986\n",
            "Epoch 12/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 111ms/step - accuracy: 0.1390 - loss: 5.1601 - val_accuracy: 0.1163 - val_loss: 6.9683\n",
            "Epoch 13/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 111ms/step - accuracy: 0.1428 - loss: 5.0607 - val_accuracy: 0.1156 - val_loss: 7.1762\n",
            "Epoch 14/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 110ms/step - accuracy: 0.1468 - loss: 4.9596 - val_accuracy: 0.1171 - val_loss: 7.4493\n",
            "Epoch 15/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 110ms/step - accuracy: 0.1523 - loss: 4.8612 - val_accuracy: 0.1191 - val_loss: 7.6174\n",
            "Epoch 16/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 110ms/step - accuracy: 0.1577 - loss: 4.7741 - val_accuracy: 0.1198 - val_loss: 7.9158\n",
            "Epoch 17/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.1645 - loss: 4.6873 - val_accuracy: 0.1167 - val_loss: 8.2007\n",
            "Epoch 18/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 111ms/step - accuracy: 0.1709 - loss: 4.6022 - val_accuracy: 0.1165 - val_loss: 8.5161\n",
            "Epoch 19/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 111ms/step - accuracy: 0.1769 - loss: 4.5357 - val_accuracy: 0.1162 - val_loss: 8.7276\n",
            "Epoch 20/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 111ms/step - accuracy: 0.1843 - loss: 4.4704 - val_accuracy: 0.1158 - val_loss: 9.0316\n",
            "Epoch 21/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 111ms/step - accuracy: 0.1927 - loss: 4.3925 - val_accuracy: 0.1151 - val_loss: 9.2631\n",
            "Epoch 22/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 111ms/step - accuracy: 0.2000 - loss: 4.3370 - val_accuracy: 0.1141 - val_loss: 9.4824\n",
            "Epoch 23/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 111ms/step - accuracy: 0.2049 - loss: 4.2758 - val_accuracy: 0.1120 - val_loss: 9.7951\n",
            "Epoch 24/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 111ms/step - accuracy: 0.2106 - loss: 4.2296 - val_accuracy: 0.1126 - val_loss: 10.0182\n",
            "Epoch 25/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 111ms/step - accuracy: 0.2180 - loss: 4.1726 - val_accuracy: 0.1100 - val_loss: 10.2336\n",
            "Epoch 26/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.2253 - loss: 4.1248 - val_accuracy: 0.1106 - val_loss: 10.4491\n",
            "Epoch 27/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.2298 - loss: 4.0807 - val_accuracy: 0.1126 - val_loss: 10.6515\n",
            "Epoch 28/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.2355 - loss: 4.0362 - val_accuracy: 0.1095 - val_loss: 10.8888\n",
            "Epoch 29/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.2419 - loss: 3.9897 - val_accuracy: 0.1059 - val_loss: 11.0190\n",
            "Epoch 30/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.2464 - loss: 3.9570 - val_accuracy: 0.1112 - val_loss: 11.2801\n",
            "Epoch 31/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.2501 - loss: 3.9096 - val_accuracy: 0.1079 - val_loss: 11.4080\n",
            "Epoch 32/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.2586 - loss: 3.8630 - val_accuracy: 0.1067 - val_loss: 11.7160\n",
            "Epoch 33/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 109ms/step - accuracy: 0.2640 - loss: 3.8139 - val_accuracy: 0.1085 - val_loss: 11.8347\n",
            "Epoch 34/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 109ms/step - accuracy: 0.2663 - loss: 3.8010 - val_accuracy: 0.1050 - val_loss: 12.0502\n",
            "Epoch 35/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 110ms/step - accuracy: 0.2761 - loss: 3.7351 - val_accuracy: 0.1062 - val_loss: 12.1711\n",
            "Epoch 36/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 109ms/step - accuracy: 0.2783 - loss: 3.7118 - val_accuracy: 0.1067 - val_loss: 12.4463\n",
            "Epoch 37/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 109ms/step - accuracy: 0.2840 - loss: 3.6681 - val_accuracy: 0.1051 - val_loss: 12.6337\n",
            "Epoch 38/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 109ms/step - accuracy: 0.2889 - loss: 3.6364 - val_accuracy: 0.1022 - val_loss: 12.8536\n",
            "Epoch 39/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 110ms/step - accuracy: 0.2924 - loss: 3.6021 - val_accuracy: 0.1060 - val_loss: 13.0454\n",
            "Epoch 40/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 110ms/step - accuracy: 0.2992 - loss: 3.5620 - val_accuracy: 0.1017 - val_loss: 13.1835\n",
            "Epoch 41/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 109ms/step - accuracy: 0.3059 - loss: 3.5276 - val_accuracy: 0.1011 - val_loss: 13.2539\n",
            "Epoch 42/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 109ms/step - accuracy: 0.3091 - loss: 3.5007 - val_accuracy: 0.0997 - val_loss: 13.5061\n",
            "Epoch 43/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 110ms/step - accuracy: 0.3123 - loss: 3.4686 - val_accuracy: 0.1000 - val_loss: 13.6948\n",
            "Epoch 44/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 109ms/step - accuracy: 0.3199 - loss: 3.4295 - val_accuracy: 0.0989 - val_loss: 13.9510\n",
            "Epoch 45/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 109ms/step - accuracy: 0.3257 - loss: 3.3886 - val_accuracy: 0.1023 - val_loss: 14.0766\n",
            "Epoch 46/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 109ms/step - accuracy: 0.3264 - loss: 3.3801 - val_accuracy: 0.0996 - val_loss: 14.2197\n",
            "Epoch 47/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 109ms/step - accuracy: 0.3333 - loss: 3.3284 - val_accuracy: 0.1001 - val_loss: 14.3174\n",
            "Epoch 48/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 109ms/step - accuracy: 0.3370 - loss: 3.3059 - val_accuracy: 0.0986 - val_loss: 14.5660\n",
            "Epoch 49/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 109ms/step - accuracy: 0.3419 - loss: 3.2698 - val_accuracy: 0.0965 - val_loss: 14.8243\n",
            "Epoch 50/50\n",
            "\u001b[1m1124/1124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 109ms/step - accuracy: 0.3470 - loss: 3.2381 - val_accuracy: 0.0990 - val_loss: 14.9833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ Generated Poetry:\n",
            " muj se pehli se mohabbat churÄ kar chale gayÄ bastiyo ab shahr e ruá¸³hsat lagÄ rakkhÄ hai miyÄÃ± tire kÅ«choÃ± meÃ± mahbÅ«b e dÄ«dÄr kar diyÄ aur kyÄ raushan ham par jalva rau sahte jÄ rahÄ huuÃ± maiÃ± kaun thÄ vo batlÄo ki mujh ko chhupÄ ke luut liyÄ duhÄÄ« hai tire kaash yaaÃ± ki\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv(\"Roman-Urdu-Poetry.csv\", usecols=[\"Poetry\"])\n",
        "\n",
        "# Clean Text Data\n",
        "def clean_poetry_text(text):\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    text = re.sub(r'[^a-zA-ZÄÄÄ“ÄŸÄ«Ã±ÅÅ«á¹£á¹­áº“á¸³á¸Œ -]', '', text)  # Remove unwanted characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "df[\"Poetry\"] = df[\"Poetry\"].apply(clean_poetry_text)\n",
        "\n",
        "# Tokenizer Setup\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df[\"Poetry\"].tolist())\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(df[\"Poetry\"].tolist())\n",
        "\n",
        "# Create input-output sequences\n",
        "input_sequences = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        input_sequences.append(seq[:i + 1])\n",
        "\n",
        "# Padding Sequences\n",
        "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Split into X and Y\n",
        "X, Y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# LSTM Model Definition\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=X_train.shape[1]),\n",
        "    LSTM(150, return_sequences=True), #long term dependencies \n",
        "    LSTM(150),\n",
        "    Dense(150, activation=\"relu\"),  \n",
        "    Dense(vocab_size, activation=\"softmax\")  #Predicts the next word using Softmax over vocabulary.\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
        "\n",
        "# Callbacks (disable EarlyStopping for all epochs to train fully)\n",
        "checkpoint = ModelCheckpoint(\"poetry_lstm_model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
        "\n",
        "# Train the Model for 50 epochs\n",
        "history = model.fit(X_train, Y_train, epochs=50, batch_size=128, validation_data=(X_val, Y_val), callbacks=[checkpoint])\n",
        "\n",
        "# Save the Model\n",
        "model.save(\"lstm_poetry_model.h5\")\n",
        "\n",
        "# Generate Poetry Function\n",
        "def generate_poetry(seed_text, next_words=50, temperature=0.8):\n",
        "    generated_text = seed_text.lower()\n",
        "    for _ in range(next_words):\n",
        "        tokenized_input = tokenizer.texts_to_sequences([generated_text])\n",
        "        tokenized_input = pad_sequences(tokenized_input, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "        predicted_probs = model.predict(tokenized_input, verbose=0)[0]\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        predicted_probs = np.log(predicted_probs + 1e-8) / temperature\n",
        "        predicted_probs = np.exp(predicted_probs) / np.sum(np.exp(predicted_probs))  # Normalize\n",
        "\n",
        "        # Sample a word based on the probabilities\n",
        "        predicted_word_index = np.random.choice(len(predicted_probs), p=predicted_probs)\n",
        "        predicted_word = tokenizer.index_word.get(predicted_word_index, \"\")\n",
        "\n",
        "        if not predicted_word:\n",
        "            break\n",
        "\n",
        "        generated_text += \" \" + predicted_word\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Example Usage\n",
        "seed_text = \"muj se pehli se mohabbat\"\n",
        "generated_poetry = generate_poetry(seed_text)\n",
        "print(\"ğŸ“ Generated Poetry:\\n\", generated_poetry)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLQImMdXcGK7",
        "outputId": "08165c72-cc41-4b25-d250-f94c114f47e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ Generated Poetry:\n",
            " awal ki dosti hai hÄl e aadÄ kahÅ«Ã± aur jo dushvÄr thÄ patthar ko to sabÄt ho yahÄ« kyÄ moÄmla kyÄ ho ki zindagÄ« ki vo chilman bhÄ« hai lekin aap aaÄ« maiÃ± aur bhÄ« kyÄ mire iá¸³htiyÄr pe pahrÄ chÄhiye us meÃ± baá¸³hshish e vafÄ se kyÄ kiije usÄ« kÄ« á¸³hair ab bhÄ«\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"awal ki dosti hai\"\n",
        "generated_poetry = generate_poetry(seed_text)\n",
        "print(\"ğŸ“ Generated Poetry:\\n\", generated_poetry)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
